{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4wg/w9J3BXHj1xNwUOnfn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgejunior618/EstudosMachineLearning/blob/main/06_Dados_Superdimensionados_Preprocessamentos_Analiticos_e_Automatizados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BPQ0GLvBvKj"
      },
      "outputs": [],
      "source": [
        "from math import isnan\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 40)\n",
        "dados = pd.read_csv('https://raw.githubusercontent.com/alura-cursos/reducao-dimensionalidade/master/data-set/exames.csv')\n",
        "SEED = 123143\n",
        "\n",
        "def malBen(diag):\n",
        "  return 0 if diag == 'M' else 1\n",
        "def nanFill(val):\n",
        "  if isnan(val): return 0\n",
        "  return val\n",
        "# dados.diagnostico = dados.diagnostico.map(malBen)\n",
        "# dados.exame_33 = dados.exame_33.map(nanFill)\n",
        "# dados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exames = dados.drop(columns=['diagnostico', 'id', 'exame_33'])\n",
        "diagnosticos = dados['diagnostico']"
      ],
      "metadata": {
        "id": "cM1zidJXDNWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Equilibrando a amostra de dados, de forma que a quantidade\n",
        "  elementos com 'Diagnostico' == 1 seja proxima das de 'Diagnostico' == 0\n",
        "'''\n",
        "\n",
        "# import seaborn as sns\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "# smt = SMOTE()\n",
        "\n",
        "# exames, diagnosticos = smt.fit_resample(exames, diagnosticos)\n",
        "# dados = pd.concat([exames, diagnosticos], axis=1)\n",
        "\n",
        "# ax = sns.countplot(x='diagnostico', data=dados, hue='diagnostico')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hy3i5u1qDBRb",
        "outputId": "f93a82c2-de8e-436f-c64a-80b5de9dbc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n  Equilibrando a amostra de dados, de forma que a quantidade\\n  elementos com 'Diagnostico' == 1 seja proxima das de 'Diagnostico' == 0\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construindo uma Visualização\n",
        "\n",
        "Importante para interpretar a distribuição dos dados e sua relação com o diagnostico do Tumor"
      ],
      "metadata": {
        "id": "ZL6BEPYIb4tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def graficoViolino(valores, vars, inicio, fim):\n",
        "  dados_plot = pd.concat([vars, valores.iloc[:,inicio:fim]], axis=1)\n",
        "  dados_plot = pd.melt( dados_plot,\n",
        "                        id_vars=\"diagnostico\",\n",
        "                        var_name=\"exames\",\n",
        "                        value_name=\"valores\")\n",
        "\n",
        "  plt.figure(figsize=(50, 15))\n",
        "  plt.xticks(rotation=90)\n",
        "  sns.violinplot(x=\"exames\", y=\"valores\", hue=\"diagnostico\", data=dados_plot, split=True)"
      ],
      "metadata": {
        "id": "G3UvnMYyDha2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocessarDadosAnalitico(data):\n",
        "  '''\n",
        "  Função que trata o conjunto de dados a ser usado no treinamento do modelo\n",
        "  de aprendizagem de maquina, de forma a utilizar somente dados relevantes\n",
        "  para a obtenção de um resultado preciso.\n",
        "_____________________________________\n",
        "  Remove as colunas que possuam uma variancia muito baixa, ou seja,\n",
        "  que seu valor é praticamente o mesmo em todas as ocorrências\n",
        "  '''\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(data)\n",
        "  data_pad = pd.DataFrame(scaler.transform(data), columns=data.columns)\n",
        "\n",
        "  dataCols = data_pad.columns\n",
        "  for ex in dataCols:\n",
        "    variancia = data_pad[ex].var() * 100\n",
        "    if data_pad[ex].max() - data_pad[ex].min() < 0.5 and variancia < 1:\n",
        "      data_pad = data_pad.drop(columns=[ex])\n",
        "  return data_pad"
      ],
      "metadata": {
        "id": "rvm7h1t4b3lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def gerarClassificadorRandomForest(valores, resultados):\n",
        "  SEED = 1234\n",
        "  treino_x, teste_x, treino_y, teste_y = train_test_split(valores, resultados, stratify=resultados, test_size=0.3, random_state=SEED)\n",
        "\n",
        "  classificador = RandomForestClassifier(n_estimators=100, random_state=SEED)\n",
        "  classificador.fit(treino_x, treino_y)\n",
        "\n",
        "  previsoes = classificador.predict(teste_x)\n",
        "\n",
        "  accuracy = accuracy_score(np.array(teste_y), previsoes) * 100\n",
        "  precision = precision_score(np.array(teste_y), previsoes, pos_label=\"B\") * 100\n",
        "  recall = recall_score(np.array(teste_y), previsoes, pos_label=\"B\") * 100\n",
        "  f1 = f1_score(np.array(teste_y), previsoes, pos_label=\"B\") * 100\n",
        "\n",
        "  return  (classificador,\n",
        "          accuracy,\n",
        "          precision,\n",
        "          recall,\n",
        "          f1)\n",
        "\n",
        "def gerarClassificadorDummy(valores, resultados):\n",
        "  SEED = 1234\n",
        "  treino_x, teste_x, treino_y, teste_y = train_test_split(valores, resultados, stratify=resultados, test_size=0.3, random_state=SEED)\n",
        "\n",
        "  classificador = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "  classificador.fit(treino_x, treino_y)\n",
        "  previsoes = classificador.predict(teste_x)\n",
        "\n",
        "  accuracy = accuracy_score(np.array(teste_y), previsoes) * 100\n",
        "  precision = precision_score(np.array(teste_y), previsoes, pos_label=\"B\") * 100\n",
        "  recall = recall_score(np.array(teste_y), previsoes, pos_label=\"B\") * 100\n",
        "  f1 = f1_score(np.array(teste_y), previsoes, pos_label=\"B\") * 100\n",
        "\n",
        "  return  (classificador,\n",
        "          accuracy,\n",
        "          precision,\n",
        "          recall,\n",
        "          f1)"
      ],
      "metadata": {
        "id": "7Od7Bh35dEUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exames_pad = preprocessarDadosAnalitico(exames)\n",
        "\n",
        "classificador, accuracyRandomForest, precisionRandomForest, recallRandomForest, f1RandomForest = gerarClassificadorRandomForest(exames_pad, diagnosticos)\n",
        "classificadorDummy, accuracyDummy, precisionDummy, recallDummy, f1Dummy = gerarClassificadorDummy(exames_pad, diagnosticos)\n",
        "\n",
        "print(\"RandomForest:\",\n",
        "      \"\\tacuracia:\\t{:.2f}%\".format(accuracyRandomForest),\n",
        "      \"\\tprecisao:\\t{:.2f}%\".format(precisionRandomForest),\n",
        "      \"\\trecall:\\t\\t{:.2f}%\".format(recallRandomForest),\n",
        "      \"\\tf1:\\t\\t{:.2f}%\".format(f1RandomForest),\n",
        "      sep=\"\\n\"\n",
        "      )\n",
        "print(\"Dummy:\",\n",
        "      \"\\tacuracia:\\t{:.2f}%\".format(accuracyDummy),\n",
        "      \"\\tprecisao:\\t{:.2f}%\".format(precisionDummy),\n",
        "      \"\\trecall:\\t\\t{:.2f}%\".format(recallDummy),\n",
        "      \"\\tf1:\\t\\t{:.2f}%\".format(f1Dummy),\n",
        "      sep=\"\\n\"\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkfzWAuaE87C",
        "outputId": "a1d56df3-eb82-4018-e417-27b79ab84c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest:\n",
            "\tacuracia:\t97.66%\n",
            "\tprecisao:\t98.13%\n",
            "\trecall:\t\t98.13%\n",
            "\tf1:\t\t98.13%\n",
            "Dummy:\n",
            "\tacuracia:\t62.57%\n",
            "\tprecisao:\t62.57%\n",
            "\trecall:\t\t100.00%\n",
            "\tf1:\t\t76.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculando a correlação entre os campos da tabela"
      ],
      "metadata": {
        "id": "FMYNV7eQnlWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocessarDadosAnaliticoV2(data):\n",
        "  '''\n",
        "  Função que trata o conjunto de dados a ser usado no treinamento do modelo\n",
        "  de aprendizagem de maquina, de forma a utilizar somente dados relevantes\n",
        "  para a obtenção de um resultado preciso.\n",
        "\n",
        "  Passo 1\n",
        "  -------\n",
        "  Remove as colunas que possuam uma variancia muito baixa, ou seja,\n",
        "  que seu valor é praticamente o mesmo em todas as ocorrências\n",
        "\n",
        "  Passo 2\n",
        "  -------\n",
        "  Remove as colunas que possuam uma alta correlação entre si\n",
        "  '''\n",
        "  # Normaliza o conjunto de dados para não haver grande\n",
        "  # dispersão entre os valores das colunas\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(data)\n",
        "  data_pad = pd.DataFrame(scaler.transform(data), columns=data.columns)\n",
        "\n",
        "  # Romevendo as colunas do conjunto de dados onde não ha grande variação\n",
        "  # de forma que seus valores não interferem na classificação\n",
        "  dataCols = data_pad.columns\n",
        "  for ex in dataCols:\n",
        "    variancia = data_pad[ex].var() * 100\n",
        "    if data_pad[ex].max() - data_pad[ex].min() < 0.5 and variancia < 1:\n",
        "      data_pad = data_pad.drop(columns=[ex])\n",
        "\n",
        "  # Obtendo os subconjuntos de dados que possuam alta correlação entre si\n",
        "  # de tal forma que há pouca diferença entre ter apenas um dos subconjuntos\n",
        "  # contidos no conjunto de treinamento\n",
        "  correlacoes = data_pad.corr()\n",
        "  correlacoesOtimas = correlacoes[correlacoes > 0.99]\n",
        "  variaveisCorrelacionadas = correlacoesOtimas.sum()\n",
        "  correlacoesOtimas = variaveisCorrelacionadas[variaveisCorrelacionadas>1]\n",
        "\n",
        "  remover = []\n",
        "  for corr in correlacoesOtimas.keys():\n",
        "    correlacoesAtual = np.array(correlacoes[correlacoes[corr] > 0.99].index)\n",
        "    for i in range(len(correlacoesAtual)-1, 0, -1):\n",
        "      remover.append(correlacoesAtual[i])\n",
        "  remover = np.unique(remover)\n",
        "  return data_pad.drop(columns=remover)"
      ],
      "metadata": {
        "id": "D6_PvY7rolyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exames_v2 = preprocessarDadosAnaliticoV2(exames)\n",
        "\n",
        "classificador, accuracyRandomForest, precisionRandomForest, recallRandomForest, f1RandomForest = gerarClassificadorRandomForest(exames_v2, diagnosticos)\n",
        "\n",
        "print(\"RandomForest:\",\n",
        "      \"\\tacuracia:\\t{:.2f}%\".format(accuracyRandomForest),\n",
        "      \"\\tprecisao:\\t{:.2f}%\".format(precisionRandomForest),\n",
        "      \"\\trecall:\\t\\t{:.2f}%\".format(recallRandomForest),\n",
        "      \"\\tf1:\\t\\t{:.2f}%\".format(f1RandomForest),\n",
        "      sep=\"\\n\"\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I13uWnuRtZR5",
        "outputId": "b367e7bd-7100-44f3-a554-cfe9be742b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest:\n",
            "\tacuracia:\t97.66%\n",
            "\tprecisao:\t97.25%\n",
            "\trecall:\t\t99.07%\n",
            "\tf1:\t\t98.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecionando os K melhores atributos\n",
        "\n",
        "Tem o objetivo de selecionar os K (valor escolhido pelo dev) atributos do conjunto de dados que melhor definem a classificação."
      ],
      "metadata": {
        "id": "w5dVlIQteroL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocessarDadosSelectKBest(data: pd.DataFrame, y) -> pd.DataFrame:\n",
        "  '''\n",
        "  Função que trata o conjunto de dados a ser usado no treinamento do modelo\n",
        "  de aprendizagem de maquina, de forma a utilizar somente dados relevantes\n",
        "  para a obtenção de um resultado preciso.\n",
        "\n",
        "  Passo 1\n",
        "  -------\n",
        "  Utiliza o modulo do sklearn SelectKBest, que seleciona os K (K=7 nesta funcao)\n",
        "  atributos que melhor descrevem a classificação para o conjunto de dados fornecido\n",
        "  '''\n",
        "  # Normaliza o conjunto de dados para não haver grande\n",
        "  # dispersão entre os valores das colunas\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(data)\n",
        "  data_pad = pd.DataFrame(scaler.transform(data), columns=data.columns)\n",
        "\n",
        "  # Obtendo os atributos de maior relevancia na classificão do conjunto de dados\n",
        "  seletorKMelhores = SelectKBest(chi2, k=5)\n",
        "  seletorKMelhores.fit(data, y)\n",
        "  seletorKMelhores.set_output(transform=\"pandas\")\n",
        "  data_pad = seletorKMelhores.transform(data_pad)\n",
        "\n",
        "  return data_pad"
      ],
      "metadata": {
        "id": "9LbdoioFfIEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exames_pad_v3 = preprocessarDadosSelectKBest(exames, diagnosticos)\n",
        "print(exames_pad_v3.shape)\n",
        "\n",
        "classificador, accuracyRandomForest, precisionRandomForest, recallRandomForest, f1RandomForest = gerarClassificadorRandomForest(exames_pad_v3, diagnosticos)\n",
        "\n",
        "print(\"RandomForest:\",\n",
        "      \"\\tacuracia:\\t{:.2f}%\".format(accuracyRandomForest),\n",
        "      \"\\tprecisao:\\t{:.2f}%\".format(precisionRandomForest),\n",
        "      \"\\trecall:\\t\\t{:.2f}%\".format(recallRandomForest),\n",
        "      \"\\tf1:\\t\\t{:.2f}%\".format(f1RandomForest),\n",
        "      sep=\"\\n\"\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qQgEgyoq38r",
        "outputId": "f48440f6-c7a8-4ba7-cb4e-b1849d23948a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 5)\n",
            "RandomForest:\n",
            "\tacuracia:\t97.66%\n",
            "\tprecisao:\t97.25%\n",
            "\trecall:\t\t99.07%\n",
            "\tf1:\t\t98.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocessarDadosRFE(data: pd.DataFrame, y) -> pd.DataFrame:\n",
        "  '''\n",
        "  Função que trata o conjunto de dados a ser usado no treinamento do modelo\n",
        "  de aprendizagem de maquina, de forma a utilizar somente dados relevantes\n",
        "  para a obtenção de um resultado preciso.\n",
        "\n",
        "  Passo 1\n",
        "  -------\n",
        "  Utiliza o modulo do sklearn RFE, que seleciona os N (N=5 nesta funcao)\n",
        "  atributos que melhor descrevem a classificação para o conjunto de dados fornecido\n",
        "  '''\n",
        "  # Normaliza o conjunto de dados para não haver grande\n",
        "  # dispersão entre os valores das colunas\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(data)\n",
        "  data_pad = pd.DataFrame(scaler.transform(data), columns=data.columns)\n",
        "\n",
        "  classificador = gerarClassificadorRandomForest(data_pad, y)[0]\n",
        "  # Obtendo os atributos de maior relevancia na classificão do conjunto de dados\n",
        "  seletorRFE = RFE(estimator=classificador, n_features_to_select=5, step=1)\n",
        "  seletorRFE.fit(data, y)\n",
        "  seletorRFE.set_output(transform=\"pandas\")\n",
        "  data_pad = seletorRFE.transform(data_pad)\n",
        "\n",
        "  return data_pad"
      ],
      "metadata": {
        "id": "HBRFrBz6KGiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exames_pad_v4 = preprocessarDadosRFE(exames, diagnosticos)\n",
        "classificador, accuracyRandomForest, precisionRandomForest, recallRandomForest, f1RandomForest = gerarClassificadorRandomForest(exames_pad_v4, diagnosticos)\n",
        "\n",
        "print(\"RandomForest:\",\n",
        "      \"\\tacuracia:\\t{:.2f}%\".format(accuracyRandomForest),\n",
        "      \"\\tprecisao:\\t{:.2f}%\".format(precisionRandomForest),\n",
        "      \"\\trecall:\\t\\t{:.2f}%\".format(recallRandomForest),\n",
        "      \"\\tf1:\\t\\t{:.2f}%\".format(f1RandomForest),\n",
        "      sep=\"\\n\"\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMcvP3qNVjcU",
        "outputId": "18bf0305-6561-40a9-bb6e-ce222a6d9c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest:\n",
            "\tacuracia:\t95.91%\n",
            "\tprecisao:\t95.45%\n",
            "\trecall:\t\t98.13%\n",
            "\tf1:\t\t96.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import get_scorer_names, make_scorer\n",
        "\n",
        "precision_score_mod = make_scorer(f1_score, pos_label=\"B\")\n",
        "def preprocessarDadosRFECV(data: pd.DataFrame, y) -> pd.DataFrame:\n",
        "  '''\n",
        "  Função que trata o conjunto de dados a ser usado no treinamento do modelo\n",
        "  de aprendizagem de maquina, de forma a utilizar somente dados relevantes\n",
        "  para a obtenção de um resultado preciso.\n",
        "\n",
        "  Passo 1\n",
        "  -------\n",
        "  Utiliza o modulo do sklearn RFECV, que seleciona os N atributos que melhor\n",
        "  descrevem a classificação para o conjunto de dados fornecido de acordo\n",
        "  com a CrossValidation executada pelo seletor\n",
        "  '''\n",
        "  # Normaliza o conjunto de dados para não haver grande\n",
        "  # dispersão entre os valores das colunas\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(data)\n",
        "  data_pad = pd.DataFrame(scaler.transform(data), columns=data.columns)\n",
        "\n",
        "  classificador = gerarClassificadorRandomForest(data_pad, y)[0]\n",
        "  seletorRFECV = RFECV(estimator=classificador, cv=5, step=1, scoring=precision_score_mod )\n",
        "  # Obtendo os atributos de maior relevancia na classificão do conjunto de dados\n",
        "  seletorRFECV.fit(data, y)\n",
        "  seletorRFECV.set_output(transform=\"pandas\")\n",
        "  data_pad = seletorRFECV.transform(data_pad)\n",
        "\n",
        "  return data_pad"
      ],
      "metadata": {
        "id": "DDXAyHHkgyFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exames_pad_v5 = preprocessarDadosRFECV(exames, diagnosticos)\n",
        "classificador, accuracyRandomForest, precisionRandomForest, recallRandomForest, f1RandomForest = gerarClassificadorRandomForest(exames_pad_v5, diagnosticos)\n",
        "\n",
        "print(\"RandomForest:\",\n",
        "      \"\\tacuracia:\\t{:.2f}%\".format(accuracyRandomForest),\n",
        "      \"\\tprecisao:\\t{:.2f}%\".format(precisionRandomForest),\n",
        "      \"\\trecall:\\t\\t{:.2f}%\".format(recallRandomForest),\n",
        "      \"\\tf1:\\t\\t{:.2f}%\".format(f1RandomForest),\n",
        "      sep=\"\\n\"\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XB5LFl5xd2V",
        "outputId": "3e20a81f-6e18-49e9-d701-2ab93ac89634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest:\n",
            "\tacuracia:\t97.66%\n",
            "\tprecisao:\t98.13%\n",
            "\trecall:\t\t98.13%\n",
            "\tf1:\t\t98.13%\n"
          ]
        }
      ]
    }
  ]
}